----------------------------------------------------------------
  Layer (type)               Output Shape         Param #
================================================================
      Conv2d-1           [-1, 64, 32, 32]           1,728
 BatchNorm2d-2           [-1, 64, 32, 32]             128
        ReLU-3           [-1, 64, 32, 32]               0
      Conv2d-4           [-1, 64, 32, 32]          36,864
 BatchNorm2d-5           [-1, 64, 32, 32]             128
        ReLU-6           [-1, 64, 32, 32]               0
   MaxPool2d-7           [-1, 64, 16, 16]               0
      Conv2d-8          [-1, 128, 16, 16]          73,728
 BatchNorm2d-9          [-1, 128, 16, 16]             256
       ReLU-10          [-1, 128, 16, 16]               0
     Conv2d-11          [-1, 128, 16, 16]         147,456
BatchNorm2d-12          [-1, 128, 16, 16]             256
       ReLU-13          [-1, 128, 16, 16]               0
  MaxPool2d-14            [-1, 128, 8, 8]               0
     Conv2d-15            [-1, 256, 8, 8]         294,912
BatchNorm2d-16            [-1, 256, 8, 8]             512
       ReLU-17            [-1, 256, 8, 8]               0
     Conv2d-18            [-1, 256, 8, 8]         589,824
BatchNorm2d-19            [-1, 256, 8, 8]             512
       ReLU-20            [-1, 256, 8, 8]               0
     Conv2d-21            [-1, 256, 8, 8]         589,824
BatchNorm2d-22            [-1, 256, 8, 8]             512
       ReLU-23            [-1, 256, 8, 8]               0
  MaxPool2d-24            [-1, 256, 4, 4]               0
     Conv2d-25            [-1, 512, 4, 4]       1,179,648		
BatchNorm2d-26            [-1, 512, 4, 4]           1,024
       ReLU-27            [-1, 512, 4, 4]               0
     Conv2d-28            [-1, 512, 4, 4]       2,359,296
BatchNorm2d-29            [-1, 512, 4, 4]           1,024
       ReLU-30            [-1, 512, 4, 4]               0
     Conv2d-31            [-1, 512, 4, 4]       2,359,296
BatchNorm2d-32            [-1, 512, 4, 4]           1,024
       ReLU-33            [-1, 512, 4, 4]               0
  MaxPool2d-34            [-1, 512, 2, 2]               0
     Conv2d-35            [-1, 512, 2, 2]       2,359,296
BatchNorm2d-36            [-1, 512, 2, 2]           1,024
       ReLU-37            [-1, 512, 2, 2]               0
     Conv2d-38            [-1, 512, 2, 2]       2,359,296
BatchNorm2d-39            [-1, 512, 2, 2]           1,024
       ReLU-40            [-1, 512, 2, 2]               0
     Conv2d-41            [-1, 512, 2, 2]       2,359,296
BatchNorm2d-42            [-1, 512, 2, 2]           1,024
       ReLU-43            [-1, 512, 2, 2]               0
     Linear-44                  [-1, 512]         262,656
BatchNorm1d-45                  [-1, 512]           1,024
       ReLU-46                  [-1, 512]               0
     Linear-47                   [-1, 10]           5,130
================================================================
Total params: 14,987,722
Trainable params: 14,987,722
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.57
Params size (MB): 57.17
Estimated Total Size (MB): 63.76
----------------------------------------------------------------
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 313463808
#Params total: 14978250
Weights: [1, 1, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 0:  ["9847f8cc0b305137f49f2c5c0c8ab25d", 1, 512, 10, 512, 10, 1, 10]
Task 1:  ["472f8f113f15cb4a194c920b6b8bb79b", 1, 512, 512, 512, 512, 512, 512, 1, 512]
Task 2:  ["96545879d5dfb7d01f882295e62002e2", 1, 2, 2, 512, 1, 1, 1, 512]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["96545879d5dfb7d01f882295e62002e2", 1, 4, 4, 512, 1, 2, 2, 512]
Task 5:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 6:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 256, 3, 3, 256, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 7:  ["96545879d5dfb7d01f882295e62002e2", 1, 8, 8, 256, 1, 4, 4, 256]
Task 8:  ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 256, 6, 6, 256, 256, 1, 1, 1, 256, 1, 8, 8, 256]
Task 9:  ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 128, 6, 6, 256, 128, 1, 1, 1, 256, 1, 8, 8, 256]
Task 10: ["96545879d5dfb7d01f882295e62002e2", 1, 16, 16, 128, 1, 8, 8, 128]
Task 11: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 128, 6, 6, 128, 128, 1, 1, 1, 128, 1, 16, 16, 128]
Task 12: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 64, 6, 6, 128, 64, 1, 1, 1, 128, 1, 16, 16, 128]
Task 13: ["96545879d5dfb7d01f882295e62002e2", 1, 32, 32, 64, 1, 16, 16, 64]
Task 14: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 64, 3, 3, 64, 64, 1, 1, 1, 64, 1, 32, 32, 64]
Task 15: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 3, 3, 3, 3, 64, 1, 1, 1, 64, 1, 32, 32, 64]
=============================== Workload_key Grouping =======================================
Task 2:  ["96545879d5dfb7d01f882295e62002e2", 1, 2, 2, 512, 1, 1, 1, 512]
Task 4:  ["96545879d5dfb7d01f882295e62002e2", 1, 4, 4, 512, 1, 2, 2, 512]
Task 7:  ["96545879d5dfb7d01f882295e62002e2", 1, 8, 8, 256, 1, 4, 4, 256]
Task 10: ["96545879d5dfb7d01f882295e62002e2", 1, 16, 16, 128, 1, 8, 8, 128]
Task 13: ["96545879d5dfb7d01f882295e62002e2", 1, 32, 32, 64, 1, 16, 16, 64]
---------------------------------------------------------------------------
Task 3[3]:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5[2]:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 6:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 256, 3, 3, 256, 512, 1, 1, 1, 512, 1, 4, 4, 512]
---------------------------------------------------------------------------
Task 8[2]:  ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 256, 6, 6, 256, 256, 1, 1, 1, 256, 1, 8, 8, 256]
Task 9:  ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 128, 6, 6, 256, 128, 1, 1, 1, 256, 1, 8, 8, 256]
---------------------------------------------------------------------------
Task 11: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 128, 6, 6, 128, 128, 1, 1, 1, 128, 1, 16, 16, 128]
Task 12: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 64, 6, 6, 128, 64, 1, 1, 1, 128, 1, 16, 16, 128]
---------------------------------------------------------------------------
Task 14: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 64, 3, 3, 64, 64, 1, 1, 1, 64, 1, 32, 32, 64]
Task 15: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 3, 3, 3, 3, 64, 1, 1, 1, 64, 1, 32, 32, 64]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.001 |          12.48 |      1 |
|    1 |        0.037 |          14.17 |      1 |
|    2 |        0.000 |           9.35 |      1 |
|    3 |        3.969 |           4.76 |      1 |
|    4 |        0.009 |           0.90 |      1 |
|    5 |        4.515 |          16.73 |      1 |
|    6 |        1.325 |          28.50 |      1 |
|    7 |        0.013 |           1.24 |      1 |
|    8 |        3.984 |           6.19 |      1 |
|    9 |        1.460 |           9.06 |      1 |
|   10 |        0.021 |           1.56 |      1 |
|   11 |        2.687 |          11.33 |      1 |
|   12 |        2.263 |           7.52 |      1 |
|   13 |        0.031 |           2.10 |      1 |
|   14 |        5.811 |          13.02 |      1 |
|   15 |        0.446 |           8.24 |      1 |
-------------------------------------------------
Estimated total latency: 43.008 ms	Trials: 16	Used time : 143 s
Latency: 28.059086 [target: 27.358]

============================== Layer 10: 448 =================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (448, 512, 3, 3) | 8257536  | 2064384 |
|   11  |  feature.37  | Conv2d | (512, 448, 3, 3) | 8257536  | 2064384 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 311104512
#Params total: 14388426
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 0:  ["9847f8cc0b305137f49f2c5c0c8ab25d", 1, 512, 10, 512, 10, 1, 10]
Task 1:  ["472f8f113f15cb4a194c920b6b8bb79b", 1, 512, 512, 512, 512, 512, 512, 1, 512]
Task 2:  ["96545879d5dfb7d01f882295e62002e2", 1, 2, 2, 512, 1, 1, 1, 512]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 448, 3, 3, 448, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 448, 512, 1, 1, 1, 448, 1, 2, 2, 448]
Task 6:  ["96545879d5dfb7d01f882295e62002e2", 1, 4, 4, 512, 1, 2, 2, 512]
Task 7:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 8:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 256, 3, 3, 256, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 9:  ["96545879d5dfb7d01f882295e62002e2", 1, 8, 8, 256, 1, 4, 4, 256]
Task 10: ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 256, 6, 6, 256, 256, 1, 1, 1, 256, 1, 8, 8, 256]
Task 11: ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 128, 6, 6, 256, 128, 1, 1, 1, 256, 1, 8, 8, 256]
Task 12: ["96545879d5dfb7d01f882295e62002e2", 1, 16, 16, 128, 1, 8, 8, 128]
Task 13: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 128, 6, 6, 128, 128, 1, 1, 1, 128, 1, 16, 16, 128]
Task 14: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 64, 6, 6, 128, 64, 1, 1, 1, 128, 1, 16, 16, 128]
Task 15: ["96545879d5dfb7d01f882295e62002e2", 1, 32, 32, 64, 1, 16, 16, 64]
Task 16: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 64, 3, 3, 64, 64, 1, 1, 1, 64, 1, 32, 32, 64]
Task 17: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 3, 3, 3, 3, 64, 1, 1, 1, 64, 1, 32, 32, 64]
=============================== Workload_key Grouping =======================================
2, 6, 9, 12, 15
3, 4, 7, 8, 16, 17
10, 11
13, 14


