+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 313463808
#Params total: 14978250
Weights: [1, 1, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 0:  ["9847f8cc0b305137f49f2c5c0c8ab25d", 1, 512, 10, 512, 10, 1, 10]
Task 1:  ["472f8f113f15cb4a194c920b6b8bb79b", 1, 512, 512, 512, 512, 512, 512, 1, 512]
Task 2:  ["96545879d5dfb7d01f882295e62002e2", 1, 2, 2, 512, 1, 1, 1, 512]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["96545879d5dfb7d01f882295e62002e2", 1, 4, 4, 512, 1, 2, 2, 512]
Task 5:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 6:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 256, 3, 3, 256, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 7:  ["96545879d5dfb7d01f882295e62002e2", 1, 8, 8, 256, 1, 4, 4, 256]
Task 8:  ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 256, 6, 6, 256, 256, 1, 1, 1, 256, 1, 8, 8, 256]
Task 9:  ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 128, 6, 6, 256, 128, 1, 1, 1, 256, 1, 8, 8, 256]
Task 10: ["96545879d5dfb7d01f882295e62002e2", 1, 16, 16, 128, 1, 8, 8, 128]
Task 11: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 128, 6, 6, 128, 128, 1, 1, 1, 128, 1, 16, 16, 128]
Task 12: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 64, 6, 6, 128, 64, 1, 1, 1, 128, 1, 16, 16, 128]
Task 13: ["96545879d5dfb7d01f882295e62002e2", 1, 32, 32, 64, 1, 16, 16, 64]
Task 14: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 64, 3, 3, 64, 64, 1, 1, 1, 64, 1, 32, 32, 64]
Task 15: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 3, 3, 3, 3, 64, 1, 1, 1, 64, 1, 32, 32, 64]
=============================== Workload_key Grouping =======================================
Task 2:  ["96545879d5dfb7d01f882295e62002e2", 1, 2, 2, 512, 1, 1, 1, 512]
Task 4:  ["96545879d5dfb7d01f882295e62002e2", 1, 4, 4, 512, 1, 2, 2, 512]
Task 7:  ["96545879d5dfb7d01f882295e62002e2", 1, 8, 8, 256, 1, 4, 4, 256]
Task 10: ["96545879d5dfb7d01f882295e62002e2", 1, 16, 16, 128, 1, 8, 8, 128]
Task 13: ["96545879d5dfb7d01f882295e62002e2", 1, 32, 32, 64, 1, 16, 16, 64]
---------------------------------------------------------------------------
Task 3[3]:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5[2]:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 6:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 256, 3, 3, 256, 512, 1, 1, 1, 512, 1, 4, 4, 512]
---------------------------------------------------------------------------
Task 8[2]:  ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 256, 6, 6, 256, 256, 1, 1, 1, 256, 1, 8, 8, 256]
Task 9:  ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 128, 6, 6, 256, 128, 1, 1, 1, 256, 1, 8, 8, 256]
---------------------------------------------------------------------------
Task 11: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 128, 6, 6, 128, 128, 1, 1, 1, 128, 1, 16, 16, 128]
Task 12: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 64, 6, 6, 128, 64, 1, 1, 1, 128, 1, 16, 16, 128]
---------------------------------------------------------------------------
Task 14: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 64, 3, 3, 64, 64, 1, 1, 1, 64, 1, 32, 32, 64] 
Task 15: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 3, 3, 3, 3, 64, 1, 1, 1, 64, 1, 32, 32, 64]
============================== All tasks ===================================
============ Task 0 (workload key: ["9847f8cc0b305137f49f2c5c0c8ab25d", 1, 512, 10, 512, 10, 1, 10]) ===========
placeholder = PLACEHOLDER [1, 512]
placeholder = PLACEHOLDER [10, 512]
T_dense(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [10]
T_add(ax0, ax1) = (T_dense[ax0, ax1] + placeholder[ax1])

============ Task 1 (workload key: ["472f8f113f15cb4a194c920b6b8bb79b", 1, 512, 512, 512, 512, 512, 512, 1, 512]) ===========
placeholder = PLACEHOLDER [1, 512]
placeholder = PLACEHOLDER [512, 512]
T_dense(i, j) += (placeholder[i, k]*placeholder[j, k])
placeholder = PLACEHOLDER [512]
T_add(ax0, ax1) = (T_dense[ax0, ax1] + placeholder[ax1])
placeholder = PLACEHOLDER [512]
T_multiply(ax0, ax1) = (T_add[ax0, ax1]*placeholder[ax1])
placeholder = PLACEHOLDER [512]
T_add(ax0, ax1) = (T_multiply[ax0, ax1] + placeholder[ax1])
T_relu(ax0, ax1) = max(T_add[ax0, ax1], 0f)

============ Task 2 (workload key: ["96545879d5dfb7d01f882295e62002e2", 1, 2, 2, 512, 1, 1, 1, 512]) ===========
placeholder = PLACEHOLDER [1, 2, 2, 512]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ((ax1*2) + rv0), ((ax2*2) + rv1), ax3]

============ Task 3 (workload key: ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 2, 2, 512]) ===========
placeholder = PLACEHOLDER [1, 2, 2, 512]
PaddedInput(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 3)) && (i2 >= 1)) && (i2 < 3)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
placeholder = PLACEHOLDER [3, 3, 512, 512]
Conv2dOutput(nn, yy, xx, ff) += (PaddedInput[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])
placeholder = PLACEHOLDER [1, 1, 1, 512]
T_add(ax0, ax1, ax2, ax3) = (Conv2dOutput[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

============ Task 4 (workload key: ["96545879d5dfb7d01f882295e62002e2", 1, 4, 4, 512, 1, 2, 2, 512]) ===========
placeholder = PLACEHOLDER [1, 4, 4, 512]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ((ax1*2) + rv0), ((ax2*2) + rv1), ax3]

============ Task 5 (workload key: ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 4, 4, 512]) ===========
placeholder = PLACEHOLDER [1, 4, 4, 512]
PaddedInput(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 5)) && (i2 >= 1)) && (i2 < 5)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
placeholder = PLACEHOLDER [3, 3, 512, 512]
Conv2dOutput(nn, yy, xx, ff) += (PaddedInput[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])
placeholder = PLACEHOLDER [1, 1, 1, 512]
T_add(ax0, ax1, ax2, ax3) = (Conv2dOutput[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

============ Task 6 (workload key: ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 256, 3, 3, 256, 512, 1, 1, 1, 512, 1, 4, 4, 512]) ===========
placeholder = PLACEHOLDER [1, 4, 4, 256]
PaddedInput(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 5)) && (i2 >= 1)) && (i2 < 5)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
placeholder = PLACEHOLDER [3, 3, 256, 512]
Conv2dOutput(nn, yy, xx, ff) += (PaddedInput[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])
placeholder = PLACEHOLDER [1, 1, 1, 512]
T_add(ax0, ax1, ax2, ax3) = (Conv2dOutput[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

============ Task 7 (workload key: ["96545879d5dfb7d01f882295e62002e2", 1, 8, 8, 256, 1, 4, 4, 256]) ===========
placeholder = PLACEHOLDER [1, 8, 8, 256]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ((ax1*2) + rv0), ((ax2*2) + rv1), ax3]

============ Task 8 (workload key: ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 256, 6, 6, 256, 256, 1, 1, 1, 256, 1, 8, 8, 256]) ===========
placeholder = PLACEHOLDER [1, 8, 8, 256]
data_pad(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 9)) && (i2 >= 1)) && (i2 < 9)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
input_tile(eps, nu, p, ci) = data_pad[floordiv(p, 4), ((floormod(floordiv(p, 2), 2)*4) + eps), ((floormod(p, 2)*4) + nu), ci]
B(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 6) == 5)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 6) == 4)),  ..(OMITTED)..  (floormod(j, 6) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 6) == 0)), 1f, 0f))))))))))))))))))))))))))))))))))))
data_pack(eps, nu, p, ci) += ((input_tile[r_a, r_b, p, ci]*B[r_a, eps])*B[r_b, nu])
placeholder = PLACEHOLDER [6, 6, 256, 256]
bgemm(eps, nu, p, co) += (data_pack[eps, nu, p, ci]*placeholder[eps, nu, co, ci])
A(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 4) == 3)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 4) == 2)),  ..(OMITTED)..  6) == 0) && (floormod(j, 4) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 4) == 0)), 1f, 0f))))))))))))))))))))))))
inverse(vh, vw, p, co) += ((bgemm[r_a, r_b, p, co]*A[r_a, vh])*A[r_b, vw])
conv2d_winograd(n, h, w, co) = inverse[floormod(h, 4), floormod(w, 4), ((((n*2)*2) + (floordiv(h, 4)*2)) + floordiv(w, 4)), co]
placeholder = PLACEHOLDER [1, 1, 1, 256]
T_add(ax0, ax1, ax2, ax3) = (conv2d_winograd[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

============ Task 9 (workload key: ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 128, 6, 6, 256, 128, 1, 1, 1, 256, 1, 8, 8, 256]) ===========
placeholder = PLACEHOLDER [1, 8, 8, 128]
data_pad(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 9)) && (i2 >= 1)) && (i2 < 9)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
input_tile(eps, nu, p, ci) = data_pad[floordiv(p, 4), ((floormod(floordiv(p, 2), 2)*4) + eps), ((floormod(p, 2)*4) + nu), ci]
B(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 6) == 5)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 6) == 4)),  ..(OMITTED)..  (floormod(j, 6) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 6) == 0)), 1f, 0f))))))))))))))))))))))))))))))))))))
data_pack(eps, nu, p, ci) += ((input_tile[r_a, r_b, p, ci]*B[r_a, eps])*B[r_b, nu])
placeholder = PLACEHOLDER [6, 6, 256, 128]
bgemm(eps, nu, p, co) += (data_pack[eps, nu, p, ci]*placeholder[eps, nu, co, ci])
A(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 4) == 3)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 4) == 2)),  ..(OMITTED)..  6) == 0) && (floormod(j, 4) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 4) == 0)), 1f, 0f))))))))))))))))))))))))
inverse(vh, vw, p, co) += ((bgemm[r_a, r_b, p, co]*A[r_a, vh])*A[r_b, vw])
conv2d_winograd(n, h, w, co) = inverse[floormod(h, 4), floormod(w, 4), ((((n*2)*2) + (floordiv(h, 4)*2)) + floordiv(w, 4)), co]
placeholder = PLACEHOLDER [1, 1, 1, 256]
T_add(ax0, ax1, ax2, ax3) = (conv2d_winograd[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

============ Task 10 (workload key: ["96545879d5dfb7d01f882295e62002e2", 1, 16, 16, 128, 1, 8, 8, 128]) ===========
placeholder = PLACEHOLDER [1, 16, 16, 128]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ((ax1*2) + rv0), ((ax2*2) + rv1), ax3]

============ Task 11 (workload key: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 128, 6, 6, 128, 128, 1, 1, 1, 128, 1, 16, 16, 128]) ===========
placeholder = PLACEHOLDER [1, 16, 16, 128]
data_pad(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 17)) && (i2 >= 1)) && (i2 < 17)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
input_tile(eps, nu, p, ci) = data_pad[floordiv(p, 16), ((floormod(floordiv(p, 4), 4)*4) + eps), ((floormod(p, 4)*4) + nu), ci]
B(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 6) == 5)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 6) == 4)),  ..(OMITTED)..  (floormod(j, 6) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 6) == 0)), 1f, 0f))))))))))))))))))))))))))))))))))))
data_pack(eps, nu, p, ci) += ((input_tile[r_a, r_b, p, ci]*B[r_a, eps])*B[r_b, nu])
placeholder = PLACEHOLDER [6, 6, 128, 128]
bgemm(eps, nu, p, co) += (data_pack[eps, nu, p, ci]*placeholder[eps, nu, co, ci])
A(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 4) == 3)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 4) == 2)),  ..(OMITTED)..  6) == 0) && (floormod(j, 4) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 4) == 0)), 1f, 0f))))))))))))))))))))))))
inverse(vh, vw, p, co) += ((bgemm[r_a, r_b, p, co]*A[r_a, vh])*A[r_b, vw])
conv2d_winograd(n, h, w, co) = inverse[floormod(h, 4), floormod(w, 4), ((((n*4)*4) + (floordiv(h, 4)*4)) + floordiv(w, 4)), co]
placeholder = PLACEHOLDER [1, 1, 1, 128]
T_add(ax0, ax1, ax2, ax3) = (conv2d_winograd[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

============ Task 12 (workload key: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 64, 6, 6, 128, 64, 1, 1, 1, 128, 1, 16, 16, 128]) ===========
placeholder = PLACEHOLDER [1, 16, 16, 64]
data_pad(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 17)) && (i2 >= 1)) && (i2 < 17)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
input_tile(eps, nu, p, ci) = data_pad[floordiv(p, 16), ((floormod(floordiv(p, 4), 4)*4) + eps), ((floormod(p, 4)*4) + nu), ci]
B(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 6) == 5)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 6) == 4)),  ..(OMITTED)..  (floormod(j, 6) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 6) == 0)), 1f, 0f))))))))))))))))))))))))))))))))))))
data_pack(eps, nu, p, ci) += ((input_tile[r_a, r_b, p, ci]*B[r_a, eps])*B[r_b, nu])
placeholder = PLACEHOLDER [6, 6, 128, 64]
bgemm(eps, nu, p, co) += (data_pack[eps, nu, p, ci]*placeholder[eps, nu, co, ci])
A(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 4) == 3)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 4) == 2)),  ..(OMITTED)..  6) == 0) && (floormod(j, 4) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 4) == 0)), 1f, 0f))))))))))))))))))))))))
inverse(vh, vw, p, co) += ((bgemm[r_a, r_b, p, co]*A[r_a, vh])*A[r_b, vw])
conv2d_winograd(n, h, w, co) = inverse[floormod(h, 4), floormod(w, 4), ((((n*4)*4) + (floordiv(h, 4)*4)) + floordiv(w, 4)), co]
placeholder = PLACEHOLDER [1, 1, 1, 128]
T_add(ax0, ax1, ax2, ax3) = (conv2d_winograd[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

============ Task 13 (workload key: ["96545879d5dfb7d01f882295e62002e2", 1, 32, 32, 64, 1, 16, 16, 64]) ===========
placeholder = PLACEHOLDER [1, 32, 32, 64]
tensor(ax0, ax1, ax2, ax3) max= placeholder[ax0, ((ax1*2) + rv0), ((ax2*2) + rv1), ax3]

============ Task 14 (workload key: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 64, 3, 3, 64, 64, 1, 1, 1, 64, 1, 32, 32, 64]) ===========
placeholder = PLACEHOLDER [1, 32, 32, 64]
PaddedInput(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 33)) && (i2 >= 1)) && (i2 < 33)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
placeholder = PLACEHOLDER [3, 3, 64, 64]
Conv2dOutput(nn, yy, xx, ff) += (PaddedInput[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])
placeholder = PLACEHOLDER [1, 1, 1, 64]
T_add(ax0, ax1, ax2, ax3) = (Conv2dOutput[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)

============ Task 15 (workload key: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 3, 3, 3, 3, 64, 1, 1, 1, 64, 1, 32, 32, 64]) ===========
placeholder = PLACEHOLDER [1, 32, 32, 3]
PaddedInput(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 33)) && (i2 >= 1)) && (i2 < 33)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)
placeholder = PLACEHOLDER [3, 3, 3, 64]
Conv2dOutput(nn, yy, xx, ff) += (PaddedInput[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])
placeholder = PLACEHOLDER [1, 1, 1, 64]
T_add(ax0, ax1, ax2, ax3) = (Conv2dOutput[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])
T_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.017 |           0.59 |      1 |
|    1 |        0.036 |          14.44 |      1 |
|    2 |        0.014 |           0.15 |      1 |
|    3 |        1.741 |          10.84 |      1 |
|    4 |        0.017 |           0.48 |      1 |
|    5 |       13.070 |           5.78 |      1 |
|    6 |        1.267 |          29.81 |      1 |
|    7 |        0.018 |           0.89 |      1 |
|    8 |        2.191 |          11.25 |      1 |
|    9 |        0.763 |          17.35 |      1 |
|   10 |        0.018 |           1.83 |      1 |
|   11 |        1.821 |          16.72 |      1 |
|   12 |        0.576 |          29.55 |      1 |
|   13 |        0.029 |           2.25 |      1 |
|   14 |        1.496 |          50.55 |      1 |
|   15 |        0.384 |           9.57 |      1 |
-------------------------------------------------
Estimated total latency: 42.202 ms	Trials: 16	Used time : 139 s
Latency: 17.154666

=================================== Layer 10 - 448 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (448, 512, 3, 3) | 8257536  | 2064384 |
|   11  |  feature.37  | Conv2d | (512, 448, 3, 3) | 8257536  | 2064384 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 311104512
#Params total: 14388426
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 0:  ["9847f8cc0b305137f49f2c5c0c8ab25d", 1, 512, 10, 512, 10, 1, 10]
Task 1:  ["472f8f113f15cb4a194c920b6b8bb79b", 1, 512, 512, 512, 512, 512, 512, 1, 512]
Task 2:  ["96545879d5dfb7d01f882295e62002e2", 1, 2, 2, 512, 1, 1, 1, 512]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 448, 3, 3, 448, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 448, 512, 1, 1, 1, 448, 1, 2, 2, 448]
Task 6:  ["96545879d5dfb7d01f882295e62002e2", 1, 4, 4, 512, 1, 2, 2, 512]
Task 7:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 8:  ["2350d19dc42a0665244368384c66b3a5", 1, 4, 4, 256, 3, 3, 256, 512, 1, 1, 1, 512, 1, 4, 4, 512]
Task 9:  ["96545879d5dfb7d01f882295e62002e2", 1, 8, 8, 256, 1, 4, 4, 256]
Task 10: ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 256, 6, 6, 256, 256, 1, 1, 1, 256, 1, 8, 8, 256]
Task 11: ["d3718cb00a3efe8f31c2b86752fb8186", 1, 8, 8, 128, 6, 6, 256, 128, 1, 1, 1, 256, 1, 8, 8, 256]
Task 12: ["96545879d5dfb7d01f882295e62002e2", 1, 16, 16, 128, 1, 8, 8, 128]
Task 13: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 128, 6, 6, 128, 128, 1, 1, 1, 128, 1, 16, 16, 128]
Task 14: ["c68f92478eb18145106184c587d212b6", 1, 16, 16, 64, 6, 6, 128, 64, 1, 1, 1, 128, 1, 16, 16, 128]
Task 15: ["96545879d5dfb7d01f882295e62002e2", 1, 32, 32, 64, 1, 16, 16, 64]
Task 16: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 64, 3, 3, 64, 64, 1, 1, 1, 64, 1, 32, 32, 64]
Task 17: ["2350d19dc42a0665244368384c66b3a5", 1, 32, 32, 3, 3, 3, 3, 64, 1, 1, 1, 64, 1, 32, 32, 64]
=============================== Workload_key Grouping =======================================
2, 6, 9, 12, 15
3, 4, 7, 8, 16, 17
10, 11
13, 14
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.024 |           0.42 |     11 |
|    1 |        0.044 |          11.85 |     11 |
|    2 |        0.001 |           3.15 |     11 |
|    3 |        1.093 |          17.28 |     11 |
|    4 |        1.105 |          14.95 |     11 |
|    5 |        2.429 |           7.94 |     11 |
|    6 |        0.003 |           3.26 |     11 |
|    7 |        2.790 |          27.07 |     11 |
|    8 |        1.906 |          19.82 |     11 |
|    9 |        0.005 |           3.13 |     11 |
|   10 |        2.948 |           8.36 |     11 |
|   11 |        1.247 |          10.61 |     11 |
|   12 |        0.012 |           2.78 |     11 |
|   13 |        1.388 |          21.93 |     11 |
|   14 |        0.562 |          30.31 |     11 |
|   15 |        0.022 |           3.04 |     11 |
|   16 |        1.788 |          42.30 |     11 |
|   17 |        0.160 |          22.87 |     11 |
-------------------------------------------------
Estimated total latency: 23.263 ms	Trials: 195	Used time : 591 s
Latency: 17.745646

=================================== Layer 10 - 416 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (416, 512, 3, 3) | 7667712  | 1916928 |
|   11  |  feature.37  | Conv2d | (512, 416, 3, 3) | 7667712  | 1916928 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 309924864
#Params total: 14093514
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 416, 3, 3, 416, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 416, 512, 1, 1, 1, 416, 1, 2, 2, 416]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.001 |           7.67 |     11 |
|    1 |        0.074 |           7.13 |     11 |
|    2 |        0.001 |           2.98 |     11 |
|    3 |        1.454 |          12.99 |     11 |
|    4 |        1.110 |          13.82 |     11 |
|    5 |        2.634 |           6.85 |     11 |
|    6 |        0.003 |           3.09 |     11 |
|    7 |        2.279 |          33.13 |     11 |
|    8 |        1.564 |          24.15 |     11 |
|    9 |        0.006 |           2.95 |     11 |
|   10 |        1.516 |          16.26 |     11 |
|   11 |        0.992 |          13.34 |     11 |
|   12 |        0.012 |           2.63 |     11 |
|   13 |        1.432 |          21.25 |     11 |
|   14 |        1.758 |           9.68 |     11 |
|   15 |        0.022 |           3.03 |     11 |
|   16 |        1.601 |          47.25 |     11 |
|   17 |        0.121 |          30.37 |     11 |
-------------------------------------------------
Estimated total latency: 20.375 ms	Trials: 195	Used time : 608 s
Latency: 17.991633

=================================== Layer 10 - 384 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (384, 512, 3, 3) | 7077888  | 1769472 |
|   11  |  feature.37  | Conv2d | (512, 384, 3, 3) | 7077888  | 1769472 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 308745216
#Params total: 13798602
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 384, 3, 3, 384, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 384, 512, 1, 1, 1, 384, 1, 2, 2, 384]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.020 |           0.50 |     11 |
|    1 |        0.055 |           9.58 |     11 |
|    2 |        0.001 |           3.15 |     11 |
|    3 |        1.685 |          11.20 |     11 |
|    4 |        1.347 |          10.51 |     11 |
|    5 |        2.531 |           6.64 |     11 |
|    6 |        0.003 |           3.09 |     11 |
|    7 |        5.930 |          12.73 |     11 |
|    8 |        2.628 |          14.37 |     11 |
|    9 |        0.006 |           2.93 |     11 |
|   10 |        1.739 |          14.18 |     11 |
|   11 |        1.687 |           7.84 |     11 |
|   12 |        0.012 |           2.76 |     11 |
|   13 |        1.541 |          19.75 |     11 |
|   14 |        1.276 |          13.34 |     11 |
|   15 |        0.022 |           3.03 |     11 |
|   16 |        3.162 |          23.92 |     11 |
|   17 |        0.110 |          33.33 |     11 |
-------------------------------------------------
Estimated total latency: 31.424 ms	Trials: 195	Used time : 602 s
Latency: 18.788391

=================================== Layer 10 - 352 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (352, 512, 3, 3) | 6488064  | 1622016 |
|   11  |  feature.37  | Conv2d | (512, 352, 3, 3) | 6488064  | 1622016 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 307565568
#Params total: 13503690
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 352, 3, 3, 352, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 352, 512, 1, 1, 1, 352, 1, 2, 2, 352]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.024 |           0.44 |     11 |
|    1 |        0.050 |          10.45 |     11 |
|    2 |        0.001 |           2.99 |     11 |
|    3 |        1.289 |          14.64 |     11 |
|    4 |        0.793 |          16.38 |     11 |
|    5 |        2.154 |           7.23 |     11 |
|    6 |        0.003 |           3.08 |     11 |
|    7 |        3.937 |          19.18 |     11 |
|    8 |        1.580 |          23.90 |     11 |
|    9 |        0.006 |           2.90 |     11 |
|   10 |        1.423 |          17.32 |     11 |
|   11 |        0.762 |          17.37 |     11 |
|   12 |        0.012 |           2.71 |     11 |
|   13 |        2.109 |          14.43 |     11 |
|   14 |        0.614 |          27.72 |     11 |
|   15 |        0.022 |           2.95 |     11 |
|   16 |        3.166 |          23.89 |     11 |
|   17 |        0.314 |          11.70 |     11 |
-------------------------------------------------
Estimated total latency: 23.618 ms	Trials: 195	Used time : 600 s
Latency: 17.7016

=================================== Layer 10 - 320 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (320, 512, 3, 3) | 5898240  | 1474560 |
|   11  |  feature.37  | Conv2d | (512, 320, 3, 3) | 5898240  | 1474560 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 306385920
#Params total: 13208778
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 320, 3, 3, 320, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 320, 512, 1, 1, 1, 320, 1, 2, 2, 320]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.001 |          10.21 |     11 |
|    1 |        0.098 |           5.39 |     11 |
|    2 |        0.001 |           3.13 |     11 |
|    3 |        1.232 |          15.33 |     11 |
|    4 |        1.013 |          11.65 |     11 |
|    5 |        2.163 |           6.63 |     11 |
|    6 |        0.003 |           3.25 |     11 |
|    7 |        4.622 |          16.34 |     11 |
|    8 |        0.927 |          40.75 |     11 |
|    9 |        0.006 |           2.95 |     11 |
|   10 |        2.850 |           8.65 |     11 |
|   11 |        0.708 |          18.69 |     11 |
|   12 |        0.012 |           2.66 |     11 |
|   13 |        2.419 |          12.58 |     11 |
|   14 |        0.566 |          30.06 |     11 |
|   15 |        0.022 |           3.01 |     11 |
|   16 |        1.247 |          60.63 |     11 |
|   17 |        0.434 |           8.46 |     11 |
-------------------------------------------------
Estimated total latency: 25.792 ms	Trials: 195	Used time : 602 s
Latency: 17.516130

=================================== Layer 10 - 288 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (288, 512, 3, 3) | 5308416  | 1327104 |
|   11  |  feature.37  | Conv2d | (512, 288, 3, 3) | 5308416  | 1327104 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 305206272
#Params total: 12913866
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 288, 3, 3, 288, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 288, 512, 1, 1, 1, 288, 1, 2, 2, 288]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.004 |           2.49 |     11 |
|    1 |        0.068 |           7.69 |     11 |
|    2 |        0.001 |           3.14 |     11 |
|    3 |        1.375 |          13.73 |     11 |
|    4 |        0.545 |          19.49 |     11 |
|    5 |        1.704 |           7.69 |     11 |
|    6 |        0.003 |           3.09 |     11 |
|    7 |        5.348 |          14.12 |     11 |
|    8 |        1.769 |          21.35 |     11 |
|    9 |        0.008 |           2.05 |     11 |
|   10 |        2.751 |           8.96 |     11 |
|   11 |        0.872 |          15.18 |     11 |
|   12 |        0.012 |           2.84 |     11 |
|   13 |        0.910 |          33.45 |     11 |
|   14 |        0.743 |          22.92 |     11 |
|   15 |        0.021 |           3.06 |     11 |
|   16 |        2.152 |          35.14 |     11 |
|   17 |        0.201 |          18.25 |     11 |
-------------------------------------------------
Estimated total latency: 26.586 ms	Trials: 195	Used time : 601 s
Latency: 16.998992

=================================== Layer 10 - 256 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (256, 512, 3, 3) | 4718592  | 1179648 |
|   11  |  feature.37  | Conv2d | (512, 256, 3, 3) | 4718592  | 1179648 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 304026624
#Params total: 12618954
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 256, 3, 3, 256, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 256, 512, 1, 1, 1, 256, 1, 2, 2, 256]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.004 |           2.44 |     11 |
|    1 |        0.042 |          12.43 |     11 |
|    2 |        0.001 |           2.99 |     11 |
|    3 |        0.833 |          22.66 |     11 |
|    4 |        0.536 |          17.62 |     11 |
|    5 |        1.456 |           8.16 |     11 |
|    6 |        0.003 |           3.26 |     11 |
|    7 |        2.820 |          26.78 |     11 |
|    8 |        1.986 |          19.02 |     11 |
|    9 |        0.005 |           3.10 |     11 |
|   10 |        2.578 |           9.56 |     11 |
|   11 |        0.659 |          20.09 |     11 |
|   12 |        0.012 |           2.66 |     11 |
|   13 |        1.362 |          22.35 |     11 |
|   14 |        0.725 |          23.48 |     11 |
|   15 |        0.022 |           3.04 |     11 |
|   16 |        2.768 |          27.33 |     11 |
|   17 |        0.081 |          45.13 |     11 |
-------------------------------------------------
Estimated total latency: 21.289 ms	Trials: 195	Used time : 589 s
Latency: 16.874661

=================================== Layer 10 - 224 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (224, 512, 3, 3) | 4128768  | 1032192 |
|   11  |  feature.37  | Conv2d | (512, 224, 3, 3) | 4128768  | 1032192 |
|   12  |  feature.40  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 302846976
#Params total: 12324042
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 4:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 224, 3, 3, 224, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 5:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 224, 512, 1, 1, 1, 224, 1, 2, 2, 224]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.002 |           6.28 |     11 |
|    1 |        0.087 |           6.08 |     11 |
|    2 |        0.001 |           3.16 |     11 |
|    3 |        1.451 |          13.01 |     11 |
|    4 |        0.614 |          13.45 |     11 |
|    5 |        1.083 |           9.82 |     11 |
|    6 |        0.003 |           3.05 |     11 |
|    7 |        3.008 |          25.11 |     11 |
|    8 |        2.438 |          15.49 |     11 |
|    9 |        0.009 |           1.90 |     11 |
|   10 |        2.414 |          10.21 |     11 |
|   11 |        0.613 |          21.57 |     11 |
|   12 |        0.012 |           2.78 |     11 |
|   13 |        2.923 |          10.41 |     11 |
|   14 |        1.122 |          15.17 |     11 |
|   15 |        0.021 |           3.05 |     11 |
|   16 |        2.824 |          26.78 |     11 |
|   17 |        0.134 |          27.32 |     11 |
-------------------------------------------------
Estimated total latency: 24.180 ms	Trials: 195	Used time : 594 s
Latency: 15.857666 (Pass, 93.27%)

=================================== Layer 11 - 448 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (448, 512, 3, 3) | 8257536  | 2064384 |
|   12  |  feature.40  | Conv2d | (512, 448, 3, 3) | 8257536  | 2064384 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 311104512
#Params total: 14388426
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 448, 3, 3, 448, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 448, 512, 1, 1, 1, 448, 1, 2, 2, 448]
Task 5:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 512, 3, 3, 512, 512, 1, 1, 1, 512, 1, 2, 2, 512]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.002 |           4.12 |     11 |
|    1 |        0.072 |           7.29 |     11 |
|    2 |        0.001 |           2.98 |     11 |
|    3 |        0.936 |          17.64 |     11 |
|    4 |        2.306 |           8.36 |     11 |
|    5 |        1.594 |          11.85 |     11 |
|    6 |        0.003 |           3.25 |     11 |
|    7 |        2.120 |          35.61 |     11 |
|    8 |        2.150 |          17.57 |     11 |
|    9 |        0.006 |           2.91 |     11 |
|   10 |        1.155 |          21.36 |     11 |
|   11 |        0.843 |          15.70 |     11 |
|   12 |        0.015 |           2.20 |     11 |
|   13 |        2.054 |          14.82 |     11 |
|   14 |        1.406 |          12.11 |     11 |
|   15 |        0.021 |           3.06 |     11 |
|   16 |        1.233 |          61.35 |     11 |
|   17 |        0.119 |          30.73 |     11 |
-------------------------------------------------
Estimated total latency: 19.310 ms	Trials: 195	Used time : 594 s
Latency: 17.498383

=================================== Layer 11 - 416 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (416, 512, 3, 3) | 7667712  | 1916928 |
|   12  |  feature.40  | Conv2d | (512, 416, 3, 3) | 7667712  | 1916928 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 309924864
#Params total: 14093514
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 416, 3, 3, 416, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 416, 512, 1, 1, 1, 416, 1, 2, 2, 416]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.022 |           0.48 |     11 |
|    1 |        0.070 |           7.49 |     11 |
|    2 |        0.001 |           2.98 |     11 |
|    3 |        0.995 |          15.42 |     11 |
|    4 |        2.994 |           6.03 |     11 |
|    5 |        0.981 |          19.25 |     11 |
|    6 |        0.003 |           3.09 |     11 |
|    7 |        4.070 |          18.55 |     11 |
|    8 |        2.440 |          15.48 |     11 |
|    9 |        0.006 |           2.94 |     11 |
|   10 |        1.745 |          14.13 |     11 |
|   11 |        0.898 |          14.73 |     11 |
|   12 |        0.012 |           2.69 |     11 |
|   13 |        0.862 |          35.31 |     11 |
|   14 |        0.895 |          19.02 |     11 |
|   15 |        0.021 |           3.05 |     11 |
|   16 |        3.858 |          19.60 |     11 |
|   17 |        0.146 |          25.13 |     11 |
-------------------------------------------------
Estimated total latency: 25.833 ms	Trials: 195	Used time : 599 s
Latency: 18.195508

=================================== Layer 11 - 384 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (384, 512, 3, 3) | 7077888  | 1769472 |
|   12  |  feature.40  | Conv2d | (512, 384, 3, 3) | 7077888  | 1769472 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 308745216
#Params total: 13798602
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 384, 3, 3, 384, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 384, 512, 1, 1, 1, 384, 1, 2, 2, 384]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.024 |           0.43 |     11 |
|    1 |        0.037 |          14.41 |     11 |
|    2 |        0.001 |           2.99 |     11 |
|    3 |        1.035 |          13.68 |     11 |
|    4 |        2.386 |           7.05 |     11 |
|    5 |        1.366 |          13.83 |     11 |
|    6 |        0.004 |           2.20 |     11 |
|    7 |        1.657 |          45.58 |     11 |
|    8 |        1.818 |          20.78 |     11 |
|    9 |        0.006 |           2.94 |     11 |
|   10 |        1.921 |          12.83 |     11 |
|   11 |        0.739 |          17.90 |     11 |
|   12 |        0.012 |           2.83 |     11 |
|   13 |        0.682 |          44.66 |     11 |
|   14 |        0.744 |          22.88 |     11 |
|   15 |        0.022 |           3.00 |     11 |
|   16 |        1.733 |          43.65 |     11 |
|   17 |        0.331 |          11.08 |     11 |
-------------------------------------------------
Estimated total latency: 18.093 ms	Trials: 195	Used time : 597 s
Latency: 18.079317

=================================== Layer 11 - 352 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (352, 512, 3, 3) | 6488064  | 1622016 |
|   12  |  feature.40  | Conv2d | (512, 352, 3, 3) | 6488064  | 1622016 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 307565568
#Params total: 13503690
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 352, 3, 3, 352, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 352, 512, 1, 1, 1, 352, 1, 2, 2, 352]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.004 |           2.47 |     11 |
|    1 |        0.060 |           8.70 |     11 |
|    2 |        0.001 |           2.99 |     11 |
|    3 |        0.533 |          24.34 |     11 |
|    4 |        2.363 |           6.59 |     11 |
|    5 |        0.834 |          22.63 |     11 |
|    6 |        0.003 |           3.08 |     11 |
|    7 |        3.845 |          19.64 |     11 |
|    8 |        1.800 |          20.98 |     11 |
|    9 |        0.007 |           2.27 |     11 |
|   10 |        2.271 |          10.86 |     11 |
|   11 |        1.154 |          11.46 |     11 |
|   12 |        0.011 |           2.86 |     11 |
|   13 |        2.411 |          12.63 |     11 |
|   14 |        0.730 |          23.33 |     11 |
|   15 |        0.022 |           2.94 |     11 |
|   16 |        4.678 |          16.17 |     11 |
|   17 |        0.265 |          13.87 |     11 |
-------------------------------------------------
Estimated total latency: 27.108 ms	Trials: 195	Used time : 599 s
Latency: 18.476355

=================================== Layer 11 - 320 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (320, 512, 3, 3) | 5898240  | 1474560 |
|   12  |  feature.40  | Conv2d | (512, 320, 3, 3) | 5898240  | 1474560 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 306385920
#Params total: 13208778
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 320, 3, 3, 320, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 320, 512, 1, 1, 1, 320, 1, 2, 2, 320]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.015 |           0.68 |     11 |
|    1 |        0.087 |           6.02 |     11 |
|    2 |        0.001 |           3.14 |     11 |
|    3 |        1.083 |          10.89 |     11 |
|    4 |        1.798 |           7.98 |     11 |
|    5 |        0.961 |          19.64 |     11 |
|    6 |        0.003 |           3.07 |     11 |
|    7 |        3.820 |          19.77 |     11 |
|    8 |        1.748 |          21.61 |     11 |
|    9 |        0.007 |           2.44 |     11 |
|   10 |        2.506 |           9.84 |     11 |
|   11 |        0.663 |          19.96 |     11 |
|   12 |        0.012 |           2.79 |     11 |
|   13 |        1.159 |          26.27 |     11 |
|   14 |        0.616 |          27.63 |     11 |
|   15 |        0.022 |           3.00 |     11 |
|   16 |        4.512 |          16.76 |     11 |
|   17 |        0.088 |          41.71 |     11 |
-------------------------------------------------
Estimated total latency: 25.426 ms	Trials: 195	Used time : 611 s
Latency: 17.911863

=================================== Layer 11 - 288 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (288, 512, 3, 3) | 5308416  | 1327104 |
|   12  |  feature.40  | Conv2d | (512, 288, 3, 3) | 5308416  | 1327104 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 305206272
#Params total: 12913866
Weights: [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]
Task 3:  ["2350d19dc42a0665244368384c66b3a5", 1, 2, 2, 288, 3, 3, 288, 512, 1, 1, 1, 512, 1, 2, 2, 512]
Task 4:  ["a543b40af283ee8e8ccfabc62b2e44e4", 1, 2, 2, 512, 6, 6, 288, 512, 1, 1, 1, 288, 1, 2, 2, 288]
----------------------------------------------------------------------
------------------------------  [ Task Scheduler ]
----------------------------------------------------------------------
|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |
-------------------------------------------------
|    0 |        0.015 |           0.69 |     11 |
|    1 |        0.050 |          10.48 |     11 |
|    2 |        0.001 |           3.13 |     11 |
|    3 |        0.862 |          12.32 |     11 |
|    4 |        1.725 |           7.60 |     11 |
|    5 |        0.821 |          22.98 |     11 |
|    6 |        0.003 |           3.25 |     11 |
|    7 |        2.607 |          28.97 |     11 |
|    8 |        1.264 |          29.87 |     11 |
|    9 |        0.006 |           2.95 |     11 |
|   10 |        1.874 |          13.16 |     11 |
|   11 |        0.578 |          22.90 |     11 |
|   12 |        0.012 |           2.85 |     11 |
|   13 |        1.705 |          17.85 |     11 |
|   14 |        0.984 |          17.31 |     11 |
|   15 |        0.029 |           2.26 |     11 |
|   16 |        1.307 |          57.85 |     11 |
|   17 |        0.084 |          43.72 |     11 |
-------------------------------------------------
Estimated total latency: 18.405 ms	Trials: 195	Used time : 623 s
Latency: 18.384034

=================================== Layer 11 - 256 =====================================
+-------+--------------+--------+------------------+----------+---------+
| Index |     Name     |  Type  |   Weight Shape   |  FLOPs   | #Params |
+-------+--------------+--------+------------------+----------+---------+
|   0   |  feature.0   | Conv2d |  (64, 3, 3, 3)   | 1769472  |   1728  |
|   1   |  feature.3   | Conv2d |  (64, 64, 3, 3)  | 37748736 |  36864  |
|   2   |  feature.7   | Conv2d | (128, 64, 3, 3)  | 18874368 |  73728  |
|   3   |  feature.10  | Conv2d | (128, 128, 3, 3) | 37748736 |  147456 |
|   4   |  feature.14  | Conv2d | (256, 128, 3, 3) | 18874368 |  294912 |
|   5   |  feature.17  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   6   |  feature.20  | Conv2d | (256, 256, 3, 3) | 37748736 |  589824 |
|   7   |  feature.24  | Conv2d | (512, 256, 3, 3) | 18874368 | 1179648 |
|   8   |  feature.27  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   9   |  feature.30  | Conv2d | (512, 512, 3, 3) | 37748736 | 2359296 |
|   10  |  feature.34  | Conv2d | (512, 512, 3, 3) | 9437184  | 2359296 |
|   11  |  feature.37  | Conv2d | (256, 512, 3, 3) | 4718592  | 1179648 |
|   12  |  feature.40  | Conv2d | (512, 256, 3, 3) | 4718592  | 1179648 |
|   13  | classifier.0 | Linear |    (512, 512)    |  262144  |  262656 |
|   14  | classifier.3 | Linear |    (10, 512)     |   5120   |   5130  |
+-------+--------------+--------+------------------+----------+---------+
FLOPs total: 304026624
#Params total: 12618954
